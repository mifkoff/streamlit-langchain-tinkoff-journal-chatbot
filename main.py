import hmac
import streamlit as st


def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if hmac.compare_digest(st.session_state["password"], st.secrets["password"]):
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    # Return True if the passward is validated.
    if st.session_state.get("password_correct", False):
        return True

    # Show input for password.
    st.text_input(
        "Password", type="password", on_change=password_entered, key="password"
    )
    if "password_correct" in st.session_state:
        st.error("üòï Password incorrect")
    return False


if not check_password():
    st.stop()

import openai
from langchain.vectorstores import Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)
import pinecone
import pandas as pd

openai_api_key = st.secrets.openai.api_key
openai_model = st.secrets.openai.model
openai_embedding_model = st.secrets.openai.embedding_model
pinecone_api_key = st.secrets.pinecone.api_key
pinecone_environment = st.secrets.pinecone.environment
pinecone_index_name = st.secrets.pinecone.index_name
pinecone_text_field = st.secrets.pinecone.text_field

openai.api_key = openai_api_key
chat = ChatOpenAI(
    openai_api_key=openai_api_key,
    model=openai_model
)
embed_model = OpenAIEmbeddings(model=openai_embedding_model, openai_api_key=openai_api_key)
pinecone.init(
    api_key=pinecone_api_key,
    environment=pinecone_environment
)
index = pinecone.Index(pinecone_index_name)
vectorstore = Pinecone(
    index, embed_model.embed_query, pinecone_text_field
)

@st.cache_data
def convert_df(df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv(index=False).encode('utf-8')

def augment_prompt(query: str):
    # get top 5 results from knowledge base
    results = vectorstore.similarity_search(query, k=5)
    # get the text from the results
    source_knowledge = "\n".join([x.page_content for x in results])
    # feed into an augmented prompt
    augmented_prompt = f"""–ò—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–µ –Ω–∏–∂–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å.

    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é:
    {source_knowledge}

    –ó–∞–ø—Ä–æ—Å: {query}"""
    return augmented_prompt, results

system_message = """
–¢—ã —Å—Ç–∞—Ä—à–∏–π –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∏–Ω—Å–∞–π—Ç—ã, –∏—Å—Ö–æ–¥—è—â–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é.
–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è —Å —ç—Ç–∏–º —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, —á—Ç–æ–±—ã –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
"""
search_result_template = """
**–°—Å—ã–ª–∫–∞:** {url}\n\n
**–ö–æ–Ω—Ç–µ–Ω—Ç:**\n
{page_content}
"""
prompt_messages = [
    SystemMessage(content=system_message.strip().replace("\n", " "))
]

st.title("üí¨ –ß–∞—Ç–±–æ—Ç: –¢–ñ —Ä–µ–º–æ–Ω—Ç")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage(content=system_message.strip().replace("\n", " "))
    ]
if "combined_data" not in st.session_state:
    st.session_state["combined_data"] = []
if "search_results" not in st.session_state:
    st.session_state["search_results"] = []

n = 0
for msg in st.session_state.messages:
    if msg.type != "system":
        st.chat_message(msg.type).write(msg.content)
        if msg.type == "ai":
            n_divider = 0
            with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                for search_result in st.session_state.search_results[n]:
                    n_divider += 1
                    st.write(search_result_template.format(
                        url=search_result.metadata["source"],
                        page_content=search_result.page_content
                    ))
                    if n_divider != 5:
                        st.divider()
            n += 1

if prompt := st.chat_input(placeholder="–í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"):
    st.chat_message("human").write(prompt)
    augmentated_prompt, search_results = augment_prompt(prompt)
    modified_prompt = HumanMessage(content=augmentated_prompt)
    st.session_state.messages.append(HumanMessage(content=prompt))
    res = chat(prompt_messages + [modified_prompt])
    st.session_state.messages.append(AIMessage(content=res.content))
    st.chat_message("ai").write(res.content)
    st.session_state["combined_data"].append({
        "question": prompt,
        "answer": res.content,
        "urls": "\n".join([x.metadata["source"] for x in search_results])
    })
    st.session_state["search_results"].append(search_results)
    n_divider = 0
    with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
        for search_result in st.session_state.search_results[-1]:
            n_divider += 1
            st.write(search_result_template.format(
                url=search_result.metadata["source"],
                page_content=search_result.page_content
            ))
            if n_divider != 5:
                st.divider()

csv = convert_df(pd.DataFrame(st.session_state["combined_data"]))
st.download_button(
    label="–°–∫–∞—á–∞—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∫—É –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã",
    data=csv,
    file_name='tinkoff-gpt-chatting.csv',
    mime='text/csv',
)